<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>YOLO V1 论文精读 | Self-Improvement</title><meta name="author" content="Vane"><meta name="copyright" content="Vane"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="首先补充一些常识 VOC数据集具有20个类别    MS COCO数据集具有80个类别 RCN对于背景信息具有更高的误判，区分背景和物体的能力差 YOLO对于背景信息和物体信息具有更好的理解，但是物体定位精读差 Abstract   单词 意义    prior 先前的   repurpose 重复使用   regression 回归   spatially 空间的   associated 相关">
<meta property="og:type" content="article">
<meta property="og:title" content="YOLO V1 论文精读">
<meta property="og:url" content="http://example.com/2025/03/04/yolov1%20-%20%E8%AE%BA%E6%96%87/index.html">
<meta property="og:site_name" content="Self-Improvement">
<meta property="og:description" content="首先补充一些常识 VOC数据集具有20个类别    MS COCO数据集具有80个类别 RCN对于背景信息具有更高的误判，区分背景和物体的能力差 YOLO对于背景信息和物体信息具有更好的理解，但是物体定位精读差 Abstract   单词 意义    prior 先前的   repurpose 重复使用   regression 回归   spatially 空间的   associated 相关">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/touxiang1.jpg">
<meta property="article:published_time" content="2025-03-04T07:41:37.036Z">
<meta property="article:modified_time" content="2025-03-06T12:55:12.698Z">
<meta property="article:author" content="Vane">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="论文精读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/touxiang1.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "YOLO V1 论文精读",
  "url": "http://example.com/2025/03/04/yolov1%20-%20%E8%AE%BA%E6%96%87/",
  "image": "http://example.com/img/touxiang1.jpg",
  "datePublished": "2025-03-04T07:41:37.036Z",
  "dateModified": "2025-03-06T12:55:12.698Z",
  "author": [
    {
      "@type": "Person",
      "name": "Vane",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/03/04/yolov1%20-%20%E8%AE%BA%E6%96%87/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'YOLO V1 论文精读',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/transpancy.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/bg1.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/touxiang1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Self-Improvement</span></a><a class="nav-page-title" href="/"><span class="site-name">YOLO V1 论文精读</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">YOLO V1 论文精读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-04T07:41:37.036Z" title="发表于 2025-03-04 15:41:37">2025-03-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-06T12:55:12.698Z" title="更新于 2025-03-06 20:55:12">2025-03-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">论文精读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img gist" style="background-image: url(/null)"></div><article class="post-content" id="article-container"><p>首先补充一些常识</p>
<p>VOC数据集具有20个类别    MS COCO数据集具有80个类别</p>
<p>RCN对于背景信息具有更高的误判，区分背景和物体的能力差</p>
<p>YOLO对于背景信息和物体信息具有更好的理解，但是物体定位精读差</p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><table>
<thead>
<tr>
<th>单词</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>prior</td>
<td>先前的</td>
</tr>
<tr>
<td>repurpose</td>
<td>重复使用</td>
</tr>
<tr>
<td>regression</td>
<td>回归</td>
</tr>
<tr>
<td>spatially</td>
<td>空间的</td>
</tr>
<tr>
<td>associated</td>
<td>相关的</td>
</tr>
<tr>
<td>unified</td>
<td>统一的</td>
</tr>
<tr>
<td>astounding</td>
<td>令人震惊的</td>
</tr>
<tr>
<td>general</td>
<td>普适的</td>
</tr>
<tr>
<td>generalizing</td>
<td>迁移泛化</td>
</tr>
<tr>
<td>domain</td>
<td>领域</td>
</tr>
</tbody></table>
<p>之前的工作都是两阶段目标检测的方法</p>
<p>YOLO将其变为了预测连续数值的regression回归问题，将其在空间上把边界框和分类概率分离了</p>
<p>是全图输入的模型，实现了端到端</p>
<p>分类成功但是定位差，不过具有更低的把背景信息误判成物体的概率</p>
<p>具有良好的迁移能力可以迁移到其他领域</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><table>
<thead>
<tr>
<th>单词</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>instantly</td>
<td>立刻</td>
</tr>
<tr>
<td>assistive</td>
<td>协助</td>
</tr>
<tr>
<td>sensor</td>
<td>传感器</td>
</tr>
<tr>
<td>robotic</td>
<td>机器人的</td>
</tr>
<tr>
<td>evenly</td>
<td>平均地</td>
</tr>
<tr>
<td>potential</td>
<td>潜在的</td>
</tr>
<tr>
<td>post-processing</td>
<td>后处理</td>
</tr>
<tr>
<td>reframe</td>
<td>重构</td>
</tr>
<tr>
<td>simultaneously</td>
<td>同时地</td>
</tr>
<tr>
<td>unified</td>
<td>统一的</td>
</tr>
<tr>
<td>latency</td>
<td>延迟</td>
</tr>
<tr>
<td>reason</td>
<td>分析</td>
</tr>
<tr>
<td>implicitly</td>
<td>隐式地</td>
</tr>
<tr>
<td>context</td>
<td>上下文</td>
</tr>
<tr>
<td>generalizable</td>
<td>泛化的</td>
</tr>
<tr>
<td>representation</td>
<td>特征表示</td>
</tr>
<tr>
<td>by a wide margin</td>
<td>大幅度</td>
</tr>
<tr>
<td>unexpected input</td>
<td>和之前分布不同的输入图像</td>
</tr>
<tr>
<td>it struggles to</td>
<td>难以</td>
</tr>
<tr>
<td>tradeoff</td>
<td>权衡</td>
</tr>
</tbody></table>
<p>当前(对于论文的当前)的目标检测系统都重复使用分类器(不同位置不同尺度的重复使用，类似于滑动窗口)</p>
<p>都是两阶段分类器-&gt;①提取潜在的候选框(region proposal) ②用分类器筛选每一个候选框 ③然后使用非极大值抑制之后微调，然后重新给每个预测框进行打分 这些都是分开进行的，每一个内容都要分别进行训练非常麻烦</p>
<p>YOLO 实现了直接从输入图像的像素空间到检测结果的映射，既可以给出分类也可以给出预测框的坐标，同时能输出多个预测框和类别</p>
<p>YOLO的优势 </p>
<ol>
<li>快 -&gt;把目标检测问题重构为了回归问题，不需要太复杂的流水线，同时能输出多个预测框和类别</li>
<li>能捕捉上下文信息 -&gt;滑动窗口和基于proposal方法只能对候选框区域的信息进行处理，但yolo是一个全局视角-&gt;Fast R-CNN会对背景有更高的误判概率 </li>
<li>迁移泛化能力好-&gt;在更换其他的输入(改变输入的分布的情况下)性能下降的概率更小</li>
</ol>
<p>YOLO的缺点-&gt;准确率低，对于小目标定位差</p>
<p><img src="/../blogimg/image-20250304192525331.png" alt="image-20250304192525331"></p>
<p>①缩放图片 ②卷积神经网络 ③后处理</p>
<h2 id="2-Unified-Detection"><a href="#2-Unified-Detection" class="headerlink" title="2. Unified Detection"></a>2. Unified Detection</h2><table>
<thead>
<tr>
<th>单词</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>unify</td>
<td>整合</td>
</tr>
<tr>
<td>component</td>
<td>组件</td>
</tr>
<tr>
<td>simultaneously</td>
<td>同时地</td>
</tr>
<tr>
<td>maintain</td>
<td>保持</td>
</tr>
<tr>
<td>formally</td>
<td>形式上</td>
</tr>
<tr>
<td>conditional class probabilities</td>
<td>类别条件概率</td>
</tr>
<tr>
<td>class-specific</td>
<td>各个类别</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>YOLO </p>
<p>→能预测全图每个框的类别→其具备挖掘全幅图片信息的能力</p>
<p>→实现端到端，实时的目标检测</p>
<p>→将图片分成S × S 个grid cell 每个 grid cell生成B个预测框</p>
<p>→ground truth(我们的人工标注框)的中心点落到哪一个grid cell中哪一个grid cell 产生的预测框bounding box来拟合ground truth→grid cell产生的预测框哪一个和ground truth的IOU更大则由哪一个框来进行预测这个ground truth</p>
<p>→每个bounding box都会有个置信度分数(与是否包含物体的概率以及离标注框的距离又多近) 其值为<img src="/../blogimg/image-20250304194528391.png" alt="image-20250304194528391">，两者成绩即为confidence的标签值，其中Pr(Object)非0即1如果框里包含物体就是1，IOU就是ground truth和预测框的交并比→如果没有物体的bounding box 的分数应该越低越好为0，负责预测的bounding box 的confidence score应该为ground truth和预测框的交并比→对于预测阶段confidence score回归出多少就是多少不需要计算这两个值，只是隐式的包含两者</p>
<p>→每个bounding box都具有五个参数(x,y,w,h,c) </p>
<p>(x,y)是中心点对于grid cell左上角的坐标 所以是∈(0,1)</p>
<p>(h,w)分别是相对于整幅图的宽高也是∈(0,1)</p>
<p>c 每个框对应的置信度得分</p>
<p>C 已包含物体的情况下各类别的概率  (每个grid cell 的所有预测bounding box 共享后面的C每个类别对应的条件概率)</p>
<p>→因此每一个grid cell有B × 5 + C 个数值</p>
<p><img src="/../blogimg/image-20250304211351537.png" alt="image-20250304211351537"></p>
<p>每个框的置信分数乘其包含物体情况下各类别的概率即可得到这个预测框对应的预测物体的真实概率，再乘与ground truth的IOU得到得分</p>
<p><strong>其他进一步讲解可以左转进入YOLO v1 技术剖析</strong></p>
<p><img src="/../blogimg/image-20250306193657819.png" alt="image-20250306193657819"></p>
<h2 id="2-1-Network-Design"><a href="#2-1-Network-Design" class="headerlink" title="2.1. Network Design"></a>2.1. Network Design</h2><table>
<thead>
<tr>
<th>单词</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>implement</td>
<td>实现</td>
</tr>
<tr>
<td>extract</td>
<td>提取(特征)</td>
</tr>
<tr>
<td>coordinate</td>
<td>坐标</td>
</tr>
<tr>
<td>other than</td>
<td>除了</td>
</tr>
</tbody></table>
<p>使用了 PASCAL VOC detection dataset</p>
<p>受到GoogleNet的启发但是没有用inception模块而是简单的3×3卷积后面跟着1×1卷积</p>
<p>Fast YOLO 和YOLO的区别是 更少的卷积层(9个) 更少的卷积核，其他的内容都和YOLO相同</p>
<p><img src="/../blogimg/image-20250306193711146.png" alt="image-20250306193711146"></p>
<p>交替的1×1卷积来减少特征空间 使用224×224×3的输入图像(ImageNet)来训练图像分类 用两倍448×448×3的图像来训练目标检测</p>
<h2 id="2-2-Training"><a href="#2-2-Training" class="headerlink" title="2.2. Training"></a>2.2. Training</h2><table>
<thead>
<tr>
<th>单词</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>comparable</td>
<td>相当的</td>
</tr>
<tr>
<td>resolution</td>
<td>分辨率</td>
</tr>
<tr>
<td>fine-grained</td>
<td>细粒度</td>
</tr>
<tr>
<td>parametrize</td>
<td>参数化</td>
</tr>
<tr>
<td>bounding box coordinates</td>
<td>框定位回归</td>
</tr>
<tr>
<td>leaky</td>
<td>泄露</td>
</tr>
<tr>
<td>sum-squared</td>
<td>平方和误差</td>
</tr>
<tr>
<td>align</td>
<td>对齐</td>
</tr>
<tr>
<td>ideal</td>
<td>适当的</td>
</tr>
<tr>
<td>overpower</td>
<td>压倒</td>
</tr>
<tr>
<td>instability</td>
<td>不确定</td>
</tr>
<tr>
<td>diverge</td>
<td>发散</td>
</tr>
<tr>
<td>remedy</td>
<td>补偿</td>
</tr>
<tr>
<td>partially</td>
<td>部分</td>
</tr>
<tr>
<td>assign</td>
<td>指定</td>
</tr>
<tr>
<td>specialization</td>
<td>特化</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>预训练 在ImageNet 1000-class数据集上训练了前二十个的卷积层(后面跟着一个全局池化AVG 以及一个全连接层)</p>
<p>根据Fast R-CNN的启发，后面加卷积层和全连接层能提升性能因此加了四个卷积层和两个全连接层(随机初始化)</p>
<p>因为目标检测是一个细粒度的视觉任务，因此将图片的分辨率提升到448×448</p>
<p>最后一层预测了类别概率和框定位坐标，并且对于坐标还有框长宽进行了归一化</p>
<p>最后一层的激活函数是线性激活函数，其他层用的全是leaky relu函数</p>
<p><img src="/../blogimg/image-20250306201834027.png" alt="image-20250306201834027"></p>
<p>使用的是优化的平方和误差损失函数(回归问题用的损失函数)</p>
<p>如果我们给不用来预测物体的框或者本身grid cell中就没落入ground truth中心点的框和用来预测物体的框具有相同的权重，那样会导致训练的发散和模型的不稳定</p>
<p>为了补偿对于定位的框的损失，我们应该加强定位误差的损失而削弱不博阿寒ground truth的预测框的confidence 损失</p>
<p>λcoord &#x3D; 5            λnoobj &#x3D; 0.5</p>
<p>大框中的小偏差比小框中的小偏差更不重要。为了部分解决这个问题，我们预测边界框宽度和高度的平方根，而不是直接预测宽度和高度</p>
<p>ground truth的中心点落入哪一个grid cell里面，那哪一个grid cell 预测出的其中一个bounding box 拟合这个ground truth ，这个bounding box 的选取是选取与ground truth 的IOU最大的bounding box，另一个bounding box需要降低置信度</p>
<p>每个框都会逐渐的特化，类似于有些就是用来预测自行车有些就是用来预测行人这种</p>
<p><img src="/../blogimg/image-20250306204518192.png" alt="image-20250306204518192"></p>
<p><strong>损失函数具体解释左转技术文档</strong></p>
<p>在 PASCAL VOC 2007 和 2012 的训练和验证数据集上训练网络大约 135 个epoch。</p>
<p>在 2012 上进行测试时，还包括 VOC 2007 测试数据以进行训练。</p>
<p>在整个训练过程中，使用 64 的批量大小、0.9 的动量和 0.0005 的衰减</p>
<p>训练过程先学习率将学习率从 10-3 提高到 10-2。如果以高学习率开始，模型经常会因梯度不稳定而发散。继续用 10-2 训练 75 个epoch，然后是 10-3 训练 30 个epoch，最后是 10-4 训练 30 个epoch</p>
<p>使用drop out 和数据增强来繁殖过拟合  </p>
<p>dropout概率为0.5</p>
<p>随机缩放和平移，最高可达原始图像大小的 20%，在 HSV 色彩空间中随机调整图像的曝光和饱和度，最高可达 1.5 倍。</p>
<p>HSV 色调 饱和度 明度</p>
</article></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/touxiang1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Vane</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/V-Ane"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">论文精读的内容并没有打上翻译，更多的是我对这一段的总结概括和理解</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Introduction"><span class="toc-number">2.</span> <span class="toc-text">1. Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Unified-Detection"><span class="toc-number">2.1.</span> <span class="toc-text">2. Unified Detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Network-Design"><span class="toc-number">2.2.</span> <span class="toc-text">2.1. Network Design</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Training"><span class="toc-number">2.3.</span> <span class="toc-text">2.2. Training</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/04/yolov1%20-%20%E8%AE%BA%E6%96%87/" title="YOLO V1 论文精读">YOLO V1 论文精读</a><time datetime="2025-03-04T07:41:37.036Z" title="发表于 2025-03-04 15:41:37">2025-03-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/03/yolov1%20-%20%E6%8A%80%E6%9C%AF/" title="YOLO V1 技术剖析">YOLO V1 技术剖析</a><time datetime="2025-03-03T07:02:01.353Z" title="发表于 2025-03-03 15:02:01">2025-03-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/26/ago%E6%8A%80%E6%9C%AF/" title="前者技术的补充">前者技术的补充</a><time datetime="2025-02-26T05:13:38.888Z" title="发表于 2025-02-26 13:13:38">2025-02-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/25/1/" title="无标题">无标题</a><time datetime="2025-02-25T12:57:57.127Z" title="发表于 2025-02-25 20:57:57">2025-02-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/25/%E7%B2%BE%E8%AF%BB%20Survey-Object%20Detection%20in%2020%20Years1/" title="精读 Survey-Object Detection in 20 Years">精读 Survey-Object Detection in 20 Years</a><time datetime="2025-02-25T12:24:13.833Z" title="发表于 2025-02-25 20:24:13">2025-02-25</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div id="footer-wrap"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>